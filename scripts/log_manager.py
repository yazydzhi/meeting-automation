#!/usr/bin/env python3
"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –ª–æ–≥–æ–≤ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –≤—Å—Ç—Ä–µ—á.
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Ä–æ—Ç–∞—Ü–∏—é, –æ—á–∏—Å—Ç–∫—É –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª–æ–≥ —Ñ–∞–π–ª–∞–º–∏.
"""

import os
import sys
import logging
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any
import argparse

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from src.config_manager import ConfigManager
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –∑–∞–ø—É—Å–∫–∞–µ—Ç–µ —Å–∫—Ä–∏–ø—Ç –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞")
    sys.exit(1)


class LogManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –ª–æ–≥–æ–≤ —Å–∏—Å—Ç–µ–º—ã."""
    
    def __init__(self, config_path: str = ".env"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –ª–æ–≥–æ–≤."""
        self.config_manager = ConfigManager(config_path)
        self.logs_dir = Path("logs")
        self.logs_dir.mkdir(exist_ok=True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        self.log_level = self.config_manager.get_general_config().get('log_level', 'INFO')
        self.retention_days = int(os.getenv('LOG_RETENTION_DAYS', '30'))
        self.max_size_mb = int(os.getenv('LOG_MAX_SIZE_MB', '100'))
        self.backup_count = int(os.getenv('LOG_BACKUP_COUNT', '5'))
        self.rotation_enabled = os.getenv('LOG_ROTATION_ENABLED', 'true').lower() == 'true'
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —Å–∞–º–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
        self._setup_logging()
    
    def _setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –ª–æ–≥–æ–≤."""
        logger = logging.getLogger("log_manager")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        self.logger = logger
    
    def get_log_files(self) -> Dict[str, Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Å–µ—Ö –ª–æ–≥ —Ñ–∞–π–ª–∞—Ö."""
        log_files = {}
        
        if not self.logs_dir.exists():
            return log_files
        
        for log_file in self.logs_dir.glob("*.log"):
            stat = log_file.stat()
            log_files[log_file.name] = {
                'path': log_file,
                'size_mb': stat.st_size / (1024 * 1024),
                'modified': datetime.fromtimestamp(stat.st_mtime),
                'age_days': (datetime.now() - datetime.fromtimestamp(stat.st_mtime)).days
            }
        
        return log_files
    
    def analyze_logs(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ª–æ–≥–æ–≤."""
        log_files = self.get_log_files()
        
        analysis = {
            'total_files': len(log_files),
            'total_size_mb': sum(info['size_mb'] for info in log_files.values()),
            'files': log_files,
            'duplicates': [],
            'old_files': [],
            'large_files': []
        }
        
        # –ü–æ–∏—Å–∫ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤
        file_types = {}
        for name, info in log_files.items():
            base_name = name.replace('.log', '').replace('_', '').lower()
            if base_name not in file_types:
                file_types[base_name] = []
            file_types[base_name].append(name)
        
        for base_name, files in file_types.items():
            if len(files) > 1:
                analysis['duplicates'].extend(files[1:])  # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª
        
        # –ü–æ–∏—Å–∫ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤
        for name, info in log_files.items():
            if info['age_days'] > self.retention_days:
                analysis['old_files'].append(name)
        
        # –ü–æ–∏—Å–∫ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
        for name, info in log_files.items():
            if info['size_mb'] > self.max_size_mb:
                analysis['large_files'].append(name)
        
        return analysis
    
    def rotate_logs(self):
        """–†–æ—Ç–∞—Ü–∏—è –ª–æ–≥ —Ñ–∞–π–ª–æ–≤."""
        if not self.rotation_enabled:
            self.logger.info("‚ö†Ô∏è –†–æ—Ç–∞—Ü–∏—è –ª–æ–≥–æ–≤ –æ—Ç–∫–ª—é—á–µ–Ω–∞")
            return
        
        log_files = self.get_log_files()
        
        for name, info in log_files.items():
            if info['size_mb'] > self.max_size_mb:
                self.logger.info(f"üîÑ –†–æ—Ç–∞—Ü–∏—è –ª–æ–≥–∞: {name} ({info['size_mb']:.1f} MB)")
                
                # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_name = f"{name}.{timestamp}"
                backup_path = self.logs_dir / backup_name
                
                try:
                    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª
                    shutil.move(info['path'], backup_path)
                    
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
                    info['path'].touch()
                    
                    self.logger.info(f"‚úÖ –õ–æ–≥ —Ä–æ—Ç–∏—Ä–æ–≤–∞–Ω: {backup_name}")
                    
                    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏
                    self._cleanup_old_backups(name)
                    
                except Exception as e:
                    self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–æ—Ç–∞—Ü–∏–∏ {name}: {e}")
    
    def _cleanup_old_backups(self, base_name: str):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π."""
        pattern = f"{base_name}.*"
        backup_files = list(self.logs_dir.glob(pattern))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
        backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ —Ñ–∞–π–ª—ã
        if len(backup_files) > self.backup_count:
            for old_file in backup_files[self.backup_count:]:
                try:
                    old_file.unlink()
                    self.logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {old_file.name}")
                except Exception as e:
                    self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {old_file.name}: {e}")
    
    def cleanup_old_logs(self):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥ —Ñ–∞–π–ª–æ–≤."""
        log_files = self.get_log_files()
        deleted_count = 0
        deleted_size = 0
        
        for name, info in log_files.items():
            if info['age_days'] > self.retention_days:
                try:
                    info['path'].unlink()
                    deleted_count += 1
                    deleted_size += info['size_mb']
                    self.logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –ª–æ–≥: {name} ({info['age_days']} –¥–Ω–µ–π)")
                except Exception as e:
                    self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {name}: {e}")
        
        if deleted_count > 0:
            self.logger.info(f"‚úÖ –û—á–∏—â–µ–Ω–æ {deleted_count} —Ñ–∞–π–ª–æ–≤, –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ {deleted_size:.1f} MB")
        else:
            self.logger.info("‚úÖ –°—Ç–∞—Ä—ã–µ –ª–æ–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    def consolidate_logs(self):
        """–ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –ª–æ–≥ —Ñ–∞–π–ª–æ–≤ –≤ –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏."""
        log_files = self.get_log_files()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ª–æ–≥–æ–≤
        main_categories = {
            'service': ['service.log', 'service_error.log'],
            'universal': ['meeting_automation_universal.log', 'universal_automation.log'],
            'audio': ['audio_processing.log', 'mp3_processing.log']
        }
        
        for category, files in main_categories.items():
            existing_files = [f for f in files if f in log_files]
            
            if len(existing_files) > 1:
                self.logger.info(f"üîÑ –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –ª–æ–≥–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category}")
                
                # –û—Å—Ç–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —É–¥–∞–ª—è–µ–º
                main_file = existing_files[0]
                files_to_delete = existing_files[1:]
                
                for file_to_delete in files_to_delete:
                    try:
                        (self.logs_dir / file_to_delete).unlink()
                        self.logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –¥—É–±–ª–∏—Ä—É—é—â–∏–π –ª–æ–≥: {file_to_delete}")
                    except Exception as e:
                        self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {file_to_delete}: {e}")
    
    def print_analysis(self):
        """–í—ã–≤–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤ –≤ –∫–æ–Ω—Å–æ–ª—å."""
        analysis = self.analyze_logs()
        
        print("\nüìä –ê–ù–ê–õ–ò–ó –õ–û–ì –§–ê–ô–õ–û–í")
        print("=" * 50)
        print(f"üìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {analysis['total_files']}")
        print(f"üíæ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {analysis['total_size_mb']:.1f} MB")
        print(f"üîÑ –†–æ—Ç–∞—Ü–∏—è: {'‚úÖ –í–∫–ª—é—á–µ–Ω–∞' if self.rotation_enabled else '‚ùå –û—Ç–∫–ª—é—á–µ–Ω–∞'}")
        print(f"‚è∞ –í—Ä–µ–º—è —Ö—Ä–∞–Ω–µ–Ω–∏—è: {self.retention_days} –¥–Ω–µ–π")
        print(f"üìè –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {self.max_size_mb} MB")
        print(f"üì¶ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π: {self.backup_count}")
        
        if analysis['files']:
            print(f"\nüìã –î–ï–¢–ê–õ–ò –§–ê–ô–õ–û–í:")
            for name, info in analysis['files'].items():
                status_icons = []
                if name in analysis['duplicates']:
                    status_icons.append("üîÑ")
                if name in analysis['duplicates']:
                    status_icons.append("‚è∞")
                if name in analysis['large_files']:
                    status_icons.append("üìè")
                
                status = " ".join(status_icons) if status_icons else "‚úÖ"
                print(f"   {status} {name}: {info['size_mb']:.1f} MB, {info['age_days']} –¥–Ω–µ–π")
        
        if analysis['duplicates']:
            print(f"\nÔøΩÔøΩ –î–£–ë–õ–ò–†–£–Æ–©–ò–ï –§–ê–ô–õ–´:")
            for duplicate in analysis['duplicates']:
                print(f"   - {duplicate}")
        
        if analysis['old_files']:
            print(f"\n‚è∞ –°–¢–ê–†–´–ï –§–ê–ô–õ–´ (> {self.retention_days} –¥–Ω–µ–π):")
            for old_file in analysis['old_files']:
                print(f"   - {old_file}")
        
        if analysis['large_files']:
            print(f"\nüìè –ë–û–õ–¨–®–ò–ï –§–ê–ô–õ–´ (> {self.max_size_mb} MB):")
            for large_file in analysis['large_files']:
                print(f"   - {large_file}")
    
    def optimize_logs(self):
        """–ü–æ–ª–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–æ–≤."""
        self.logger.info("üöÄ –ù–∞—á–∏–Ω–∞—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–æ–≤...")
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.print_analysis()
        
        # –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤
        self.logger.info("\nüîÑ –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –ª–æ–≥ —Ñ–∞–π–ª–æ–≤...")
        self.consolidate_logs()
        
        # –†–æ—Ç–∞—Ü–∏—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
        self.logger.info("\nüîÑ –†–æ—Ç–∞—Ü–∏—è –±–æ–ª—å—à–∏—Ö –ª–æ–≥ —Ñ–∞–π–ª–æ–≤...")
        self.rotate_logs()
        
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤
        self.logger.info("\nüóëÔ∏è –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥ —Ñ–∞–π–ª–æ–≤...")
        self.cleanup_old_logs()
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        self.logger.info("\nüìä –§–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏...")
        self.print_analysis()
        
        self.logger.info("‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ª–æ–≥–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    parser = argparse.ArgumentParser(description="–ú–µ–Ω–µ–¥–∂–µ—Ä –ª–æ–≥–æ–≤ —Å–∏—Å—Ç–µ–º—ã –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –≤—Å—Ç—Ä–µ—á")
    parser.add_argument("--config", default=".env", help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
    parser.add_argument("--action", choices=["analyze", "rotate", "cleanup", "consolidate", "optimize"], 
                       default="analyze", help="–î–µ–π—Å—Ç–≤–∏–µ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
    parser.add_argument("--retention-days", type=int, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π —Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–æ–≥–æ–≤")
    parser.add_argument("--max-size-mb", type=int, help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ª–æ–≥ —Ñ–∞–π–ª–∞ –≤ MB")
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –ª–æ–≥–æ–≤
    log_manager = LogManager(args.config)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    if args.retention_days:
        log_manager.retention_days = args.retention_days
    if args.retention_days:
        log_manager.max_size_mb = args.max_size_mb
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
    if args.action == "analyze":
        log_manager.print_analysis()
    elif args.action == "rotate":
        log_manager.rotate_logs()
    elif args.action == "cleanup":
        log_manager.cleanup_old_logs()
    elif args.action == "consolidate":
        log_manager.consolidate_logs()
    elif args.action == "optimize":
        log_manager.optimize_logs()


if __name__ == "__main__":
    main()
