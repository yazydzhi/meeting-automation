#!/usr/bin/env python3
"""–¢–µ—Å—Ç Energy –∏ Adaptive —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å –ª–æ–∫–∞–ª—å–Ω—ã–º Whisper"""

import os
import sys
import time
import json
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.append(str(Path(__file__).parent / 'src'))

def test_local_whisper_segmentation():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º Energy –∏ Adaptive —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é —Å –ª–æ–∫–∞–ª—å–Ω—ã–º Whisper"""
    print("üéØ –¢–ï–°–¢ ENERGY –ò ADAPTIVE –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–ò + –õ–û–ö–ê–õ–¨–ù–´–ô WHISPER")
    print("=" * 70)
    
    # –ê—É–¥–∏–æ —Ñ–∞–π–ª –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    audio_file = "data/temp_audio/–ê–ª—å—Ñ–∞ –Ω–µ–∏–ø–æ—Ç–µ—á–Ω—ã–µ —Å–¥–µ–ª–∫–∏ –≤—Ç–æ—Ä–∏—á–∫–∞ 01.08.2025 —á2_compressed_prepared_compressed.wav"
    
    if not os.path.exists(audio_file):
        print(f"‚ùå –ê—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_file}")
        return
    
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º AudioProcessor
        from audio_processor import AudioProcessor
        
        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Å –ª–æ–∫–∞–ª—å–Ω—ã–º Whisper
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é AudioProcessor —Å –ª–æ–∫–∞–ª—å–Ω—ã–º Whisper...")
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ Whisper
        os.environ['TRANSCRIPTION_METHOD'] = 'whisper'
        os.environ['WHISPER_MODEL_LOCAL'] = 'base'
        
        processor = AudioProcessor()
        print(f"‚úÖ –ú–µ—Ç–æ–¥ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {processor.transcription_method}")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º Energy —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é
        print("\n‚ö° –¢–µ—Å—Ç–∏—Ä—É—é Energy —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é...")
        print("-" * 50)
        
        start_time = time.time()
        energy_result = processor.process_audio_file_with_advanced_segmentation(audio_file, 'energy')
        energy_time = time.time() - start_time
        
        if energy_result:
            print(f"‚úÖ Energy —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {energy_time:.2f}—Å")
            print(f"üìä –°–µ–≥–º–µ–Ω—Ç–æ–≤: {energy_result.get('total_segments', 0)}")
            print(f"üë• –°–ø–∏–∫–µ—Ä–æ–≤: {len(energy_result.get('speakers', {}))}")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            analyze_transcriptions(energy_result, 'energy')
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            save_segmentation_result(audio_file, 'energy', energy_result, energy_time)
        else:
            print("‚ùå Energy —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º Adaptive —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é
        print("\nüß† –¢–µ—Å—Ç–∏—Ä—É—é Adaptive —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é...")
        print("-" * 50)
        
        start_time = time.time()
        adaptive_result = processor.process_audio_file_with_advanced_segmentation(audio_file, 'adaptive')
        adaptive_time = time.time() - start_time
        
        if adaptive_result:
            print(f"‚úÖ Adaptive —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {adaptive_time:.2f}—Å")
            print(f"üìä –°–µ–≥–º–µ–Ω—Ç–æ–≤: {adaptive_result.get('total_segments', 0)}")
            print(f"üë• –°–ø–∏–∫–µ—Ä–æ–≤: {len(adaptive_result.get('speakers', {}))}")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            analyze_transcriptions(adaptive_result, 'adaptive')
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            save_segmentation_result(audio_file, 'adaptive', adaptive_result, adaptive_time)
        else:
            print("‚ùå Adaptive —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if energy_result and adaptive_result:
            compare_results(energy_result, adaptive_result, energy_time, adaptive_time)
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

def analyze_transcriptions(result: dict, method_name: str):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π"""
    print(f"\nüìù –ê–ù–ê–õ–ò–ó –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–ô ({method_name.upper()}):")
    
    raw_transcriptions = result.get('raw_transcriptions', [])
    if not raw_transcriptions:
        print("‚ùå –ù–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º
    total_text_length = 0
    segment_lengths = []
    empty_segments = 0
    
    for trans in raw_transcriptions:
        text = trans.get('text', '')
        text_length = len(text)
        total_text_length += text_length
        segment_lengths.append(text_length)
        
        if text_length == 0:
            empty_segments += 1
    
    print(f"üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(raw_transcriptions)}")
    print(f"   ‚Ä¢ –ü—É—Å—Ç—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {empty_segments}")
    print(f"   ‚Ä¢ –û–±—â–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {total_text_length} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞: {total_text_length / len(raw_transcriptions):.1f} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–ª–∏–Ω–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    if segment_lengths:
        min_length = min(segment_lengths)
        max_length = max(segment_lengths)
        print(f"   ‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {min_length} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {max_length} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤
    print(f"\nüìã –ü—Ä–∏–º–µ—Ä—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π:")
    for i, trans in enumerate(raw_transcriptions[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
        text = trans.get('text', '')
        start_time = trans.get('start_time', 0)
        end_time = trans.get('end_time', 0)
        duration = trans.get('duration', 0)
        
        print(f"   –°–µ–≥–º–µ–Ω—Ç {i+1}: [{start_time}ms - {end_time}ms] ({duration}ms)")
        print(f"   –¢–µ–∫—Å—Ç: {text[:100]}{'...' if len(text) > 100 else ''}")
        print()

def save_segmentation_result(audio_file: str, method: str, result: dict, processing_time: float):
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏"""
    try:
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        base_name = os.path.splitext(os.path.basename(audio_file))[0]
        output_dir = Path(f'data/audio_processing/{base_name}_local_whisper_test/{method}')
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ JSON
        json_file = output_dir / 'result.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            # –£–±–∏—Ä–∞–µ–º numpy –º–∞—Å—Å–∏–≤—ã –¥–ª—è JSON
            json_result = {}
            for key, value in result.items():
                if key == 'raw_transcriptions':
                    json_result[key] = []
                    for trans in value:
                        json_trans = {
                            'segment': trans.get('segment'),
                            'start_time': trans.get('start_time'),
                            'end_time': trans.get('end_time'),
                            'duration': trans.get('duration'),
                            'text': trans.get('text'),
                            'segmentation_method': trans.get('segmentation_method')
                        }
                        json_result[key].append(json_trans)
                elif key == 'speakers':
                    json_result[key] = {}
                    for speaker, segments in value.items():
                        json_result[key][speaker] = []
                        for seg in segments:
                            json_seg = {
                                'segment': seg.get('segment'),
                                'start_time': seg.get('start_time'),
                                'end_time': seg.get('end_time'),
                                'duration': seg.get('duration'),
                                'text': seg.get('text')
                            }
                            json_result[key][speaker].append(json_seg)
                else:
                    json_result[key] = value
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            json_result['processing_time'] = processing_time
            json_result['method'] = method
            
            json.dump(json_result, f, ensure_ascii=False, indent=2)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ TXT
        txt_file = output_dir / 'transcript.txt'
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(f"–¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–Ø: {method.upper()} –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–Ø + –õ–û–ö–ê–õ–¨–ù–´–ô WHISPER\n")
            f.write(f"–§–∞–π–ª: {audio_file}\n")
            f.write(f"–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.get('processed_at', '')}\n")
            f.write(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {processing_time:.2f}—Å\n")
            f.write(f"–°–µ–≥–º–µ–Ω—Ç–æ–≤: {result.get('total_segments', 0)}\n")
            f.write(f"–°–ø–∏–∫–µ—Ä–æ–≤: {len(result.get('speakers', {}))}\n")
            f.write(f"–ú–µ—Ç–æ–¥ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {result.get('segmentation_method', 'unknown')}\n")
            f.write("-" * 80 + "\n\n")
            
            for trans in result.get('raw_transcriptions', []):
                f.write(f"[{trans.get('start_time', 0)}ms - {trans.get('end_time', 0)}ms] ")
                f.write(f"–°–µ–≥–º–µ–Ω—Ç {trans.get('segment', '?')} ({trans.get('segmentation_method', 'unknown')})\n")
                f.write(f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {trans.get('duration', 0)}ms\n")
                f.write(f"–¢–µ–∫—Å—Ç: {trans.get('text', '')}\n")
                f.write("-" * 40 + "\n\n")
        
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_dir}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ {method}: {e}")

def compare_results(energy_result: dict, adaptive_result: dict, energy_time: float, adaptive_time: float):
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–≤—É—Ö –º–µ—Ç–æ–¥–æ–≤"""
    print("\n" + "=" * 70)
    print("üìä –°–†–ê–í–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("=" * 70)
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    energy_segments = energy_result.get('total_segments', 0)
    adaptive_segments = adaptive_result.get('total_segments', 0)
    
    print(f"üî¢ –ö–û–õ–ò–ß–ï–°–¢–í–û –°–ï–ì–ú–ï–ù–¢–û–í:")
    print(f"   ‚Ä¢ Energy: {energy_segments}")
    print(f"   ‚Ä¢ Adaptive: {adaptive_segments}")
    print(f"   ‚Ä¢ –†–∞–∑–Ω–∏—Ü–∞: {abs(energy_segments - adaptive_segments)}")
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    print(f"\n‚è±Ô∏è –í–†–ï–ú–Ø –û–ë–†–ê–ë–û–¢–ö–ò:")
    print(f"   ‚Ä¢ Energy: {energy_time:.2f}—Å")
    print(f"   ‚Ä¢ Adaptive: {adaptive_time:.2f}—Å")
    print(f"   ‚Ä¢ –†–∞–∑–Ω–∏—Ü–∞: {abs(energy_time - adaptive_time):.2f}—Å")
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π
    energy_transcriptions = energy_result.get('raw_transcriptions', [])
    adaptive_transcriptions = adaptive_result.get('raw_transcriptions', [])
    
    energy_text_length = sum(len(t.get('text', '')) for t in energy_transcriptions)
    adaptive_text_length = sum(len(t.get('text', '')) for t in adaptive_transcriptions)
    
    print(f"\nüìù –ö–ê–ß–ï–°–¢–í–û –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–ô:")
    print(f"   ‚Ä¢ Energy: {energy_text_length} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   ‚Ä¢ Adaptive: {adaptive_text_length} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   ‚Ä¢ –†–∞–∑–Ω–∏—Ü–∞: {abs(energy_text_length - adaptive_text_length)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤
    energy_speakers = len(energy_result.get('speakers', {}))
    adaptive_speakers = len(adaptive_result.get('speakers', {}))
    
    print(f"\nüë• –ö–û–õ–ò–ß–ï–°–¢–í–û –°–ü–ò–ö–ï–†–û–í:")
    print(f"   ‚Ä¢ Energy: {energy_speakers}")
    print(f"   ‚Ä¢ Adaptive: {adaptive_speakers}")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    if energy_segments > adaptive_segments:
        print("   ‚Ä¢ Energy –¥–∞–µ—Ç –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—É—é —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é")
    else:
        print("   ‚Ä¢ Adaptive –¥–∞–µ—Ç –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—É—é —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é")
    
    if energy_time < adaptive_time:
        print("   ‚Ä¢ Energy —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–µ–µ")
    else:
        print("   ‚Ä¢ Adaptive —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–µ–µ")
    
    if energy_text_length > adaptive_text_length:
        print("   ‚Ä¢ Energy –¥–∞–µ—Ç –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏")
    else:
        print("   ‚Ä¢ Adaptive –¥–∞–µ—Ç –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏")
    
    print(f"\nüìÅ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: data/audio_processing/[–∏–º—è_—Ñ–∞–π–ª–∞]_local_whisper_test/")

if __name__ == "__main__":
    test_local_whisper_segmentation()
