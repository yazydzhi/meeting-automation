#!/usr/bin/env python3
"""
Audio Processor with Whisper Integration
–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenAI Whisper API
–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
"""

import os
import sys
import json
import logging
import argparse
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime
import tempfile
import shutil

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.config_manager import ConfigManager

try:
    import openai
    # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º pydub –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    # from pydub import AudioSegment
    # from pydub.silence import split_on_silence
    print("‚ö†Ô∏è Pydub –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install openai pydub")
    sys.exit(1)


class AudioProcessor:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤ —Å Whisper –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤"""
    
    def __init__(self, config_path: Optional[str] = None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –∞—É–¥–∏–æ"""
        self.config = ConfigManager(config_path)
        self.setup_logging()
        self.setup_openai()
        self.setup_directories()
        
    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        log_level = self.config.get('LOG_LEVEL', 'INFO')
        log_file = self.config.get('LOG_FILE', 'logs/audio_processing.log')
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        
        logging.basicConfig(
            level=getattr(logging, log_level.upper()),
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def setup_openai(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI API"""
        api_key = self.config.get('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            
        openai.api_key = api_key
        
        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é
        org_id = self.config.get('OPENAI_ORGANIZATION')
        if org_id:
            openai.organization = org_id
            
        self.logger.info("OpenAI API –Ω–∞—Å—Ç—Ä–æ–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        
    def setup_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        dirs = [
            self.config.get('AUDIO_PROCESSING_ROOT', 'data/audio_processing'),
            self.config.get('TRANSCRIPT_OUTPUT_ROOT', 'data/transcripts'),
            self.config.get('TEMP_AUDIO_ROOT', 'data/temp_audio')
        ]
        
        for dir_path in dirs:
            os.makedirs(dir_path, exist_ok=True)
            self.logger.debug(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ–∑–¥–∞–Ω–∞/–ø—Ä–æ–≤–µ—Ä–µ–Ω–∞: {dir_path}")
            
    def process_audio_file(self, audio_path: str, output_format: str = 'json') -> Dict:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞ —Å Whisper
        
        Args:
            audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            output_format: –§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ ('json', 'txt', 'srt')
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        self.logger.info(f"–ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞: {audio_path}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"–ê—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")
            
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Whisper
        model = self.config.get('WHISPER_MODEL', 'base')
        language = self.config.get('WHISPER_LANGUAGE', 'ru')
        task = self.config.get('WHISPER_TASK', 'transcribe')
        
        try:
            # –í—Ä–µ–º–µ–Ω–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            self.logger.info("‚ö†Ô∏è Pydub –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞—é –∑–∞–≥–ª—É—à–∫—É")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–ª—É—à–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result = {
                'file_path': audio_path,
                'file_size': os.path.getsize(audio_path),
                'duration': 0,  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –∫–æ–≥–¥–∞ pydub –∑–∞—Ä–∞–±–æ—Ç–∞–µ—Ç
                'segments_count': 1,
                'speakers_count': 1,
                'transcription': [{
                    'speaker_id': '–£—á–∞—Å—Ç–Ω–∏–∫ 1',
                    'segments': [{
                        'text': '[Pydub –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è]',
                        'start_time': 0,
                        'end_time': 0,
                        'duration': 0
                    }],
                    'total_duration': 0
                }],
                'processing_time': datetime.now().isoformat(),
                'whisper_model': model,
                'language': language
            }
            
            # –ù–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ - —ç—Ç–æ –¥–µ–ª–∞–µ—Ç –≤—ã–∑—ã–≤–∞—é—â–∏–π –∫–æ–¥
            # self._save_result(result, output_format)
            
            self.logger.info("‚ö†Ô∏è –ó–∞–≥–ª—É—à–∫–∞ —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            return result
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ: {e}")
            raise
            
    def _split_audio_by_silence(self, audio: Any) -> List[Dict]:
        """
        –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∞—É–¥–∏–æ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ —Ç–∏—à–∏–Ω–µ
        
        Args:
            audio: –ê—É–¥–∏–æ —Å–µ–≥–º–µ–Ω—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
        min_silence_len = int(self.config.get('SPEAKER_MIN_DURATION', 1.0) * 1000)
        silence_thresh = int(self.config.get('SPEAKER_SILENCE_THRESHOLD', 0.5) * 1000)
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ —Ç–∏—à–∏–Ω–µ
        chunks = split_on_silence(
            audio,
            min_silence_len=min_silence_len,
            silence_thresh=silence_thresh,
            keep_silence=True
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        segments = []
        current_time = 0
        
        for i, chunk in enumerate(chunks):
            duration = len(chunk)
            segment = {
                'segment_id': i + 1,
                'audio_data': chunk,
                'start_time': current_time,
                'end_time': current_time + duration,
                'duration': duration
            }
            segments.append(segment)
            current_time += duration
            
        return segments
        
    def _save_segment_temp(self, segment: Dict, index: int) -> str:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        
        Args:
            segment: –°–µ–≥–º–µ–Ω—Ç –∞—É–¥–∏–æ
            index: –ò–Ω–¥–µ–∫—Å —Å–µ–≥–º–µ–Ω—Ç–∞
            
        Returns:
            –ü—É—Ç—å –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        temp_dir = self.config.get('TEMP_AUDIO_ROOT', 'data/temp_audio')
        temp_file = os.path.join(temp_dir, f"segment_{index:03d}.mp3")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç
        segment['audio_data'].export(temp_file, format='mp3')
        return temp_file
        
    def _transcribe_with_whisper(self, audio_file: str, model: str, language: str, task: str) -> Dict:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é Whisper API
        
        Args:
            audio_file: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            model: –ú–æ–¥–µ–ª—å Whisper
            language: –Ø–∑—ã–∫ –∞—É–¥–∏–æ
            task: –¢–∏–ø –∑–∞–¥–∞—á–∏ (transcribe/translate)
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        """
        try:
            with open(audio_file, 'rb') as f:
                response = openai.Audio.transcribe(
                    model=f"whisper-{model}",
                    file=f,
                    language=language,
                    task=task,
                    response_format="verbose_json"
                )
                
            return {
                'text': response.get('text', ''),
                'language': response.get('language', language),
                'segments': response.get('segments', []),
                'confidence': response.get('confidence', 0.0)
            }
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ Whisper API: {e}")
            return {
                'text': f"[–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}]",
                'language': language,
                'segments': [],
                'confidence': 0.0
            }
            
    def _group_by_speakers(self, transcriptions: List[Dict]) -> List[Dict]:
        """
        –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π –ø–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º
        
        Args:
            transcriptions: –°–ø–∏—Å–æ–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π
            
        Returns:
            –°–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø –ø–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º
        """
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ –º–µ–∂–¥—É —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏ –±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ - –Ω–æ–≤—ã–π —É—á–∞—Å—Ç–Ω–∏–∫
        speaker_groups = []
        current_speaker = []
        current_speaker_id = 1
        
        for i, trans in enumerate(transcriptions):
            if i == 0:
                current_speaker.append(trans)
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—É–∑—É –º–µ–∂–¥—É —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏
                pause_duration = trans['start_time'] - transcriptions[i-1]['end_time']
                
                # –ï—Å–ª–∏ –ø–∞—É–∑–∞ –±–æ–ª—å—à–µ –ø–æ—Ä–æ–≥–∞ - –Ω–æ–≤—ã–π —É—á–∞—Å—Ç–Ω–∏–∫
                if pause_duration > 2000:  # 2 —Å–µ–∫—É–Ω–¥—ã
                    if current_speaker:
                        speaker_groups.append({
                            'speaker_id': f"–£—á–∞—Å—Ç–Ω–∏–∫ {current_speaker_id}",
                            'segments': current_speaker,
                            'total_duration': sum(s['duration'] for s in current_speaker)
                        })
                        current_speaker_id += 1
                        current_speaker = []
                        
                current_speaker.append(trans)
                
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞
        if current_speaker:
            speaker_groups.append({
                'speaker_id': f"–£—á–∞—Å—Ç–Ω–∏–∫ {current_speaker_id}",
                'segments': current_speaker,
                'total_duration': sum(s['duration'] for s in current_speaker)
            })
            
        return speaker_groups
        
    def _save_result(self, result: Dict, output_format: str):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ —Ñ–∞–π–ª
        
        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
            output_format: –§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞
        """
        output_dir = self.config.get('TRANSCRIPT_OUTPUT_ROOT', 'data/transcripts')
        base_name = os.path.splitext(os.path.basename(result['file_path']))[0]
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if output_format == 'json':
            output_file = os.path.join(output_dir, f"{base_name}_{timestamp}.json")
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
                
        elif output_format == 'txt':
            output_file = os.path.join(output_dir, f"{base_name}_{timestamp}.txt")
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞: {result['file_path']}\n")
                f.write(f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {result['duration']}ms\n")
                f.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {result['segments_count']}\n")
                f.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {result['speakers_count']}\n")
                f.write("=" * 50 + "\n\n")
                
                for speaker in result['transcription']:
                    f.write(f"{speaker['speaker_id']}:\n")
                    for segment in speaker['segments']:
                        f.write(f"[{segment['start_time']}-{segment['end_time']}ms] {segment['text']}\n")
                    f.write("\n")
                    
        elif output_format == 'srt':
            output_file = os.path.join(output_dir, f"{base_name}_{timestamp}.srt")
            with open(output_file, 'w', encoding='utf-8') as f:
                subtitle_id = 1
                for speaker in result['transcription']:
                    for segment in speaker['segments']:
                        start_time = self._ms_to_srt_time(segment['start_time'])
                        end_time = self._ms_to_srt_time(segment['end_time'])
                        
                        f.write(f"{subtitle_id}\n")
                        f.write(f"{start_time} --> {end_time}\n")
                        f.write(f"{speaker['speaker_id']}: {segment['text']}\n\n")
                        subtitle_id += 1
                        
        self.logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
        
    def _ms_to_srt_time(self, milliseconds: int) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥ –≤ —Ñ–æ—Ä–º–∞—Ç SRT –≤—Ä–µ–º–µ–Ω–∏"""
        seconds = milliseconds // 1000
        ms = milliseconds % 1000
        
        hours = seconds // 3600
        minutes = (seconds % 3600) // 60
        secs = seconds % 60
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{ms:03d}"
        
    def cleanup_temp_files(self):
        """–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        temp_dir = self.config.get('TEMP_AUDIO_ROOT', 'data/temp_audio')
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
            os.makedirs(temp_dir)
            self.logger.info("–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –æ—á–∏—â–µ–Ω—ã")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(description='–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ —Å Whisper')
    parser.add_argument('audio_file', help='–ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É')
    parser.add_argument('--config', help='–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É')
    parser.add_argument('--output', choices=['json', 'txt', 'srt'], default='json',
                       help='–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: json)')
    parser.add_argument('--cleanup', action='store_true', help='–û—á–∏—Å—Ç–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã')
    parser.add_argument('--verbose', '-v', action='store_true', help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥')
    
    args = parser.parse_args()
    
    try:
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        processor = AudioProcessor(args.config)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
        result = processor.process_audio_file(args.audio_file, args.output)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if args.verbose:
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            print(f"üìÅ –§–∞–π–ª: {result['file_path']}")
            print(f"‚è±Ô∏è  –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {result['duration']}ms")
            print(f"üîä –°–µ–≥–º–µ–Ω—Ç–æ–≤: {result['segments_count']}")
            print(f"üë• –£—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {result['speakers_count']}")
            
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if args.cleanup:
            processor.cleanup_temp_files()
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()
